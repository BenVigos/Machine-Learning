{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Assignment 3: K-means\n",
    "\n",
    "### Names of group members (max 2):\n",
    "    Boris (Johnson)\n",
    "    Joe (Biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing the required modules\n",
    "%pip install numpy matplotlib #installs them if they are not yet there\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# to get matplot figures render correctly in the notebook use:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Part 1: Coding and testing the Kmeans algorithm\n",
    "\n",
    "### Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## the data set for testing\n",
    "\n",
    "df = np.array([ [12, 20, 28, 18, 29, 33, 24, 45, 45, 52, 51, 52, 55, 53, 55, 61, 64, 69, 72],\n",
    "                [39, 36, 30, 52, 54, 46, 55, 59, 63, 70, 66, 63, 58, 23, 14, 8, 19, 7, 24] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick scatterplot for yourself, can you imagine what the cluster should be?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "### Method 1. Using Kmeans form package sklearn.\n",
    "\n",
    "<ul>\n",
    "    <li> Make a plot function that gives the same colour to data points within one cluster. \n",
    "    </li>\n",
    "    <li> Call KMeans from the package. (Consult the sklearn manual online and figure out how to do it.)\n",
    "    </li>\n",
    "    <li> Plot next to the data points also the centres of the clusters ($Z_j$)\n",
    "    </li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 3 ## the number of clusters\n",
    "\n",
    "def plotclusters(data, k):\n",
    "...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Method 2. Code yourself: A heuristic, simple, fast, pretty good algorithm.\n",
    "\n",
    "<ol>\n",
    "    <li> Initialization. Choose k random points as centres; plot the data black, the three centers in colour\n",
    "    </li>\n",
    "    <li> Function: assigmnent. Compute for every data point the closest centre: assign the data point to that cluster.\n",
    "    </li>\n",
    "    <li> Function: replace. Put all centres as the average of the data in their cluster.\n",
    "    </li>\n",
    "    <li> Script. Repeat assignment, replace, plotclusters until nothing changes. \n",
    "    </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1. Initialization.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2. Function: assigmnent.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3. Function: assigmnent.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 4. Script.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Part 2: Apply Kmeans to Wines database\n",
    "    \n",
    "### Let's start by thanking the creators of the dataset that we will be using:\n",
    "\n",
    "Cortez,Paulo, Cerdeira,A., Almeida,F., Matos,T., and Reis,J.. (2009). Wine Quality. UCI Machine Learning Repository. https://doi.org/10.24432/C56S3T.\n",
    "\n",
    "## Loading and Inspecting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing the required modules\n",
    "%pip install numpy matplotlib seaborn pandas scikit-learn #installs them if they are not yet there\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# to get matplot figures render correctly in the notebook use:\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "rwine = pd.read_csv('winequality-red.csv', sep=';')  # Makes Pandas objects\n",
    "wwine = pd.read_csv('winequality-white.csv', sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You may analyse the dataset of the wine of your choosing (red or white):\n",
    "wines = 'your wine here'.sample(frac = 1)\n",
    "\n",
    "# We just drop the 'quality' from the dataset:\n",
    "wines_noquality=wines.drop('quality', axis=1)\n",
    "# the number of samples M in the total combined set is still the same\n",
    "M = len(wines_noquality)\n",
    "# the number of features N (excluding the bias) are now all (excluding f='quality'):\n",
    "N =  wines_noquality.shape[1]\n",
    "wines_noquality.head() # We will use everything you see here.\n",
    "X=np.zeros((M,N))\n",
    "X[0:M,0:N]=wines_noquality[:][0:M]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Prepare the data and reduce the dimensionelity of the feature space\n",
    "\n",
    "<ol>\n",
    "    <li>Feature scaling of all features in the database</li>\n",
    "    <li>Do a Principle Component Analysis (PCA)</li>\n",
    "    <li>Reduce the dimensionality of the feature space to 2 by projecting your samples along the first 2 principle component vector</li>\n",
    "    <li>Plot your samples as a scatter plot in 2d</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: feature scaling\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: PCA analyis\n",
    "from sklearn.decomposition import PCA\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Project samples along PCA directions\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Scatterplot of sample in 2d plane spanned by the first 2 PCA vectors\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Kmeans cluster analysis in the plane spanned by the first 2 PCA vectors\n",
    "\n",
    "<ol>\n",
    "    <li>Do Kmeans clustering with either method 1 or method 2</li>\n",
    "    <li>As a function of the number of centroids, plot the average distance of each sample to its centroid </li>\n",
    "    <li>Determine a sensible number of clusters and explain why. You could try the 'elbow method'. What is the problem with not knowing the number of clusters? </li>\n",
    "    <li>Plot the clusters in a scatterpot with different colors</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1:  Kmeans clustering \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2:  Average distance to the k centroids\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Determine optimal k value\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
